{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46f14ae-3472-4c82-b812-100d2b9ebd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "import csv\n",
    "import re\n",
    "import progressbar\n",
    "\n",
    "# Data Analysis\n",
    "import pandas\n",
    "import tabulate\n",
    "import seaborn\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "# Short hack for display of images in jupyter notebook\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>div.output_area pre {white-space: pre;}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f262d43f-974b-4e47-ac16-da74d9892c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGS_DIR = \"figs\"\n",
    "def save_figure(fig, ext=\".png\"):\n",
    "    \"\"\"Stores @p fig at `figs/fig.@ext`\"\"\"\n",
    "    tgt_dir = os.path.join(DATA_SOURCE, FIGS_DIR)\n",
    "    tgt = os.path.join(tgt_dir, fig + ext)    \n",
    "    if not os.path.exists(tgt_dir):\n",
    "        os.makedirs(tgt_dir)\n",
    "    print(f\"Saving to {tgt}\")\n",
    "    if ext == \".png\":\n",
    "        plt.savefig(tgt, backend=\"cairo\", bbox_inches=\"tight\", pad_inches=0.2)\n",
    "    else:\n",
    "        plt.savefig(tgt, bbox_inches=\"tight\", pad_inches=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35703b5-9d3c-4f16-bf63-9a29c870a4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./data/\"\n",
    "for experiment_dir in os.listdir(DATA_DIR):\n",
    "    full_path = os.path.join(DATA_DIR, experiment_dir)\n",
    "    if os.path.isdir(full_path):\n",
    "        print(f'DATA_SOURCE = \"{full_path}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d298ce7-c10d-4197-a450-6ba3f5a7f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE = \"./data/experiments-10-07\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e768b8d-1e22-4fcf-9b8f-e8f9394b9844",
   "metadata": {},
   "source": [
    "## Creating DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e252f0b-cd6e-4615-99b9-914296df4104",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERR = 60\n",
    "TIMEOUT = 60\n",
    "\n",
    "def to_operation(src, lang):\n",
    "    op = src.split('-')[-1]\n",
    "    if 'runtime' in op:\n",
    "        return 'runtime'\n",
    "    elif 'overall' in op:\n",
    "        return 'overall'\n",
    "    elif 'interpretation' in op:\n",
    "        return 'interpretation'\n",
    "    elif 'deter' in op:\n",
    "        return 'determization'\n",
    "    elif 'minterm' in op:\n",
    "        return 'minterm'\n",
    "    elif 'reduce' in op:\n",
    "        return 'reduce'\n",
    "    elif 'inter' in op:\n",
    "        return 'intersection'\n",
    "    elif 'union' in op or 'uni' in op:\n",
    "        return 'union'\n",
    "    elif ('construction' in op and lang != 'c++') or 'parsing' in op:\n",
    "        return 'parsing'\n",
    "    elif ('construction' in op and lang == 'c++') or 'conversion' in op:\n",
    "        return 'transform'\n",
    "    elif 'concat' in op:\n",
    "        return 'concatenation'\n",
    "    elif 'result' in op:\n",
    "        return 'result'\n",
    "    elif 'inclusion_check' == op or 'inclusion' == op:\n",
    "        return 'inclusion'\n",
    "    elif 'emptiness_check' == op or 'emptiness' == op:\n",
    "        return 'emptiness'\n",
    "    elif 'compl' == op or 'complementation' == op or 'complement' == op:\n",
    "        return 'complement'\n",
    "    elif 'trim' in op:\n",
    "        return 'trim'\n",
    "    print(f\"{src} unhandled\")\n",
    "    assert False\n",
    "\n",
    "def to_tool_and_lang(tool):\n",
    "    if 'mata-bin' in tool or 'stats' in tool:\n",
    "        return None, None\n",
    "    elif 'mata-0.111' in tool:\n",
    "        return \"mata-0.111\", \"c++\"\n",
    "    elif 'mata-0.112' in tool:\n",
    "        return \"mata-0.112\", \"c++\"\n",
    "    elif 'mata-0.113' in tool:\n",
    "        return \"mata-0.113\", \"c++\"\n",
    "    elif 'mata-sim' in tool:\n",
    "        return \"mata-sim\", \"c++\"\n",
    "    elif 'mata-old' in tool:\n",
    "        return \"mata-old\", \"c++\"\n",
    "    elif 'awali' in tool:\n",
    "        return 'awali', 'c++'\n",
    "    elif 'mona' in tool:\n",
    "        return 'mona', 'c++'\n",
    "    elif 'vata' in tool:\n",
    "        return 'vata', 'c++'\n",
    "    elif 'java-brics' in tool:\n",
    "        return 'brics', 'java'\n",
    "    elif 'java-automata' in tool:\n",
    "        return '(j)alib', 'java'\n",
    "    elif 'pyfado' in tool:\n",
    "        return 'fado', 'python'\n",
    "    elif 'pyautomata-lib' in tool:\n",
    "        return '(py)alib', 'python'\n",
    "    elif 'pymata' in tool:\n",
    "        return '(py)mata', 'python'\n",
    "    elif 'automata' in tool:\n",
    "        return 'automata', 'c#'\n",
    "    elif 'mata' in tool:\n",
    "        return 'mata', 'c++'\n",
    "    print(f\"{tool} unhandled\")\n",
    "    assert False\n",
    "\n",
    "def to_bench(bench, src):\n",
    "    if 'automata_inclusion' in bench:\n",
    "        return 'aut_inclusion'\n",
    "    elif 'comb/ere' in bench:\n",
    "        return 'bc_ere'\n",
    "    elif ('cox/diff' in bench or 'cox/inter' in bench) and 'union' in src :\n",
    "        return 'bc_cox_union'\n",
    "    elif ('cox/diff' in bench or 'cox/inter' in bench) and 'cox-inter' in src :\n",
    "        return 'bc_cox_inter'\n",
    "    elif ('cox/diff' in bench or 'cox/inter' in bench) and 'cox-diff' in src :\n",
    "        return 'bc_cox_diff'\n",
    "    elif 'email_filter' in bench:\n",
    "        return 'email_filter'\n",
    "    elif 'z3-noodler' in bench:\n",
    "        if 'concat' in src:\n",
    "            return 'z3_noodler_concat'\n",
    "        elif 'intersect' in src:\n",
    "            return 'z3_noodler_intersect'\n",
    "        else:\n",
    "            return 'z3_noodler'\n",
    "    elif 'presburger-explicit' in bench:\n",
    "        return 'presburger-explicit'\n",
    "    elif 'presburger' in bench:\n",
    "        return 'presburger'\n",
    "    elif 'intersect' in bench:\n",
    "        return 'bc_intersect' if 'union' not in src else 'bc_intersect_union'\n",
    "    print(f\"{bench} unhandled\")\n",
    "    assert False\n",
    "\n",
    "def to_value(val):\n",
    "    val = val.strip()\n",
    "    try:\n",
    "        return float(val)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    if val in ['EMPTY', \"NOT EMPTY\"]:\n",
    "        return val\n",
    "    elif val in ('false', 'False'):\n",
    "        return 'false'\n",
    "    elif val in ('true', 'True'):\n",
    "        return 'true'\n",
    "    elif val == 'ERR':\n",
    "        return 'ERR'\n",
    "    elif val == 'MISSING':\n",
    "        return numpy.NAN\n",
    "    elif val == 'TIMEOUT' or val == 'TO':\n",
    "        return TIMEOUT\n",
    "    print(f\"{val} unhandled\")\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b1f1d9-ff65-4aa9-9ae4-78b319db16c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = [\"bench\", \"input\", \"tool\", \"lang\", \"op\", \"time\"]\n",
    "TIMEOUT = 60\n",
    "TIMEOUT_REGEX = re.compile(\"timeout-(\\d+)\")\n",
    "processed = defaultdict(set)\n",
    "op_map = defaultdict(list)\n",
    "bench_map = defaultdict(set)\n",
    "def to_pandas(src_dir):\n",
    "    global TIMEOUT\n",
    "    data = []\n",
    "    for csv_source in progressbar.progressbar(os.listdir(src_dir)):\n",
    "        if csv_source.endswith('.csv'):\n",
    "            if timeout := TIMEOUT_REGEX.search(csv_source):\n",
    "                TIMEOUT = int(timeout.group(1))\n",
    "            with open(os.path.join(src_dir, csv_source), 'r', newline='') as csvfile:\n",
    "                try:\n",
    "                    csv_reader = csv.reader(csvfile, delimiter=';')\n",
    "                    head = next(csv_reader)\n",
    "                    for row in csv_reader:\n",
    "                        bench = to_bench(row[0], csv_source) # bench\n",
    "                        bench_map[(row[0], bench)].add(csv_source)\n",
    "                        inputs = row[0] # inputs\n",
    "                        for i, val in enumerate(row[1:], 1):\n",
    "                            tool, lang = to_tool_and_lang(head[i]) # tool, lang\n",
    "                            if not tool:\n",
    "                                continue\n",
    "                            op = to_operation(head[i], lang) # op\n",
    "                            op_map[op].append(head[i])\n",
    "                            val = to_value(val)\n",
    "                            data.append([bench, inputs, tool, lang, op, val])\n",
    "                except StopIteration:\n",
    "                    pass\n",
    "    return pandas.DataFrame(data, columns=HEADERS)\n",
    "df = to_pandas(DATA_SOURCE)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28b6a00-3862-4f4d-8d40-04705049cab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'bench': [],\n",
    "    'input': [],\n",
    "    'tool': [],\n",
    "    'lang': [],\n",
    "    'op': [],\n",
    "    'time': []\n",
    "}\n",
    "def to_float(val, default=0):\n",
    "    vals = list(val)\n",
    "    if val.empty:\n",
    "        if default == None:\n",
    "            print(f\"{val=}, {vals=}\")\n",
    "            assert False\n",
    "        return default\n",
    "    if len(vals) != 1:\n",
    "        print(f\"{vals=}\")\n",
    "        assert False\n",
    "    try:\n",
    "        return float(vals[0])\n",
    "    except:\n",
    "        return 0 if str(vals[0]) not in ('ERR', 'TIMEOUT') else TIMEOUT\n",
    "for grp, series in df.groupby(['bench', 'input', 'tool']):\n",
    "    data['bench'].append(grp[0])\n",
    "    data['input'].append(grp[1])\n",
    "    data['tool'].append(grp[2])\n",
    "    data['lang'].append(list(series['lang'])[0])\n",
    "    data['op'].append('fair-overall')\n",
    "\n",
    "    pyco_runtime = list(series[series['op'] == 'runtime']['time'])\n",
    "    if len(pyco_runtime) != 1:\n",
    "        print(f\"{list(series.items())=}\")\n",
    "        print(f\"{pyco_runtime=}\")\n",
    "        assert False\n",
    "    if pyco_runtime[0] == TIMEOUT or pyco_runtime[0] == 'ERR':\n",
    "        data['time'].append(TIMEOUT)\n",
    "        continue\n",
    "        \n",
    "    \n",
    "    runtime = to_float(series[series['op'] == 'overall']['time'], None)\n",
    "    parsing = to_float(series[series['op'] == 'parsing']['time'], 0)\n",
    "    transform = to_float(series[series['op'] == 'transform']['time'], 0)\n",
    "    fair_runtime = runtime - parsing - transform\n",
    "    if grp[2] == 'mona':\n",
    "        data['time'].append(runtime)\n",
    "    else:\n",
    "        data['time'].append(fair_runtime)\n",
    "ddf = pandas.DataFrame(data)\n",
    "df = pandas.concat([df, ddf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c159f8-fc68-4871-bc95-d7a7f16976d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_generator(series, timeout=None):\n",
    "    \"\"\"Cumulatively sums the @p series wrt @p timeout\"\"\"\n",
    "    sum = 0\n",
    "    series = sorted(\n",
    "        [a if isinstance(a, float) or isinstance(a, int) else numpy.NAN for a in series['time']],\n",
    "        key = lambda x: float('inf') if numpy.isnan(x) else x\n",
    "    )\n",
    "    for num in sorted(series):\n",
    "        if numpy.isnan(num):\n",
    "            yield None\n",
    "        if timeout and num >= timeout:\n",
    "            yield None\n",
    "        else:\n",
    "            sum += num\n",
    "            yield sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea06ab5d-51a7-4f03-958f-2d0e8a6fdcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = sorted(t for t in set(df['tool']))\n",
    "tool_len = len(tools)\n",
    "color_map = {\n",
    "    t: c for (t, c) in zip(tools, mpl.colormaps['tab20'].resampled(tool_len).colors)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f450fc1b-447f-4f56-a482-52abd4196781",
   "metadata": {},
   "source": [
    "### Final visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a869cf-76b0-488e-9265-fe49cc7773b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_list = sorted(list(set(list(df['bench']))))\n",
    "item_no = len(bench_list)\n",
    "x_dim = item_no // 3 + 1\n",
    "y_dim = min(item_no, 3)\n",
    "for op in ('runtime', 'fair-overall'):\n",
    "    fig, ax = plt.subplots(x_dim, y_dim, figsize=(x_dim * 5, y_dim * 6))\n",
    "    plt.subplots_adjust(top=0.99, bottom=0.01, hspace=0.2, wspace=0.10)\n",
    "    \n",
    "    for grp in bench_list:\n",
    "        series = df[df['bench'] == grp]\n",
    "        series = series[series['op'] == 'fair-overall']\n",
    "        i = bench_list.index(grp)\n",
    "        grp_name = f\"{grp}\"\n",
    "        \n",
    "        data = {}\n",
    "        for tool, values in series.groupby('tool'):\n",
    "            data[tool] = list(sum_generator(values, timeout=TIMEOUT))\n",
    "            \n",
    "        g = seaborn.lineplot(\n",
    "            data, linewidth=3.5, palette=color_map, dashes=\"\", ax=ax[i // 3, i % 3] if item_no > 1 else ax\n",
    "        )\n",
    "        \n",
    "        g.set(yscale=\"linear\")\n",
    "        g.set_xticklabels(g.get_xticklabels(), rotation=30)\n",
    "        g.set_title(f\"{grp}\", x=0.05)\n",
    "        if i % 3 == 0:\n",
    "            g.set_ylabel(\"time [s]\")\n",
    "        if i // 3 == 2:\n",
    "            g.set_xlabel(\"benchmark\")\n",
    "        \n",
    "        seaborn.move_legend(g, \"upper left\", bbox_to_anchor=(0., 1), frameon=True)\n",
    "        x_lim_min, x_lim_max = g.get_xlim()\n",
    "        g.set_xlim((x_lim_min, x_lim_max))\n",
    "    \n",
    "    save_figure(f\"paper-cactus-plot-per-bench-{op}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734a39a6-9c79-4636-bbdb-721cdb7c0d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "op_list = sorted(list(set(list(df['op']))))\n",
    "print(f\"available: {op_list}\")\n",
    "op_list = [\n",
    "    'complement', 'concatenation', 'determization', \n",
    "    'emptiness', 'fair-overall', 'inclusion', \n",
    "    'interpretation', 'intersection', 'minterm', \n",
    "    'overall', 'parsing', 'reduce', \n",
    "    'runtime', 'transform', 'trim', 'union'\n",
    "]\n",
    "item_no = len(op_list)\n",
    "x_dim = item_no // 3 + 1\n",
    "y_dim = min(item_no, 3)\n",
    "fig, ax = plt.subplots(x_dim, y_dim, figsize=(x_dim * 5, y_dim * 6))\n",
    "plt.subplots_adjust(top=0.99, bottom=0.01, hspace=0.2, wspace=0.10)\n",
    "\n",
    "for grp in op_list:\n",
    "    series = df[df['op'] == grp]\n",
    "    i = op_list.index(grp)\n",
    "    grp_name = f\"{grp}\"\n",
    "    \n",
    "    data = {}\n",
    "    for tool, values in series.groupby('tool'):\n",
    "        data[tool] = list(sum_generator(values, timeout=TIMEOUT))\n",
    "        \n",
    "    g = seaborn.lineplot(\n",
    "        data, linewidth=3.5, palette=color_map, dashes=\"\", ax=ax[i // 3, i % 3] if item_no > 1 else ax\n",
    "    )\n",
    "    \n",
    "    g.set(yscale=\"logit\")\n",
    "    g.set_xticklabels(g.get_xticklabels(), rotation=30)\n",
    "    g.set_title(f\"{grp}\", x=0.05)\n",
    "    if i % 3 == 0:\n",
    "        g.set_ylabel(\"time [s]\")\n",
    "    if i // 3 == 2:\n",
    "        g.set_xlabel(\"benchmark\")\n",
    "    \n",
    "    seaborn.move_legend(g, \"upper left\", bbox_to_anchor=(0., 1), frameon=True)\n",
    "    x_lim_min, x_lim_max = g.get_xlim()\n",
    "    g.set_xlim((x_lim_min, x_lim_max))\n",
    "\n",
    "save_figure(f\"paper-cactus-plot-per-operation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af39d8e-8f75-41f6-8101-af375634ce74",
   "metadata": {},
   "source": [
    "### Rest of the visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2559904d-66af-4794-9804-3992447fb72d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def to_table(df, rows, aggregation, trim_rows=False, trimsize=5):\n",
    "    tools = ['mata', 'mata-0.111', 'mata-0.112', 'mata-0.113', 'mata-old', 'mata-sim', 'awali', 'mona', 'vata',  'automata', 'brics', '(j)alib', 'fado', '(py)alib', '(py)mata']\n",
    "    tools = [t for t in tools if t in set(df['tool'])]\n",
    "    data = {\n",
    "        grp: [grp[:trimsize] if trim_rows else grp] + ['-' for i in range(len(tools))] for grp in set(df[rows]) if grp != 'result' and 'result' not in grp\n",
    "    }\n",
    "    for grp, series in df.groupby([rows, 'tool'] if not isinstance(rows, list) else rows + tools):\n",
    "        if grp[0] == 'result' or 'result' in grp[0]:\n",
    "            continue\n",
    "        vals = aggregation(series['time'])\n",
    "        data[grp[0]][tools.index(grp[1]) + 1] = \", \".join(vals)\n",
    "    return tabulate.tabulate(\n",
    "        sorted(data.values()), headers=[rows] + tools\n",
    "    )\n",
    "\n",
    "def to_printable_table(table, title):\n",
    "    table_len = len(table.split('\\n')[1])\n",
    "    printable = title.center(table_len) + \"\\n\"\n",
    "    printable += \"-\" * table_len + \"\\n\"\n",
    "    printable += table\n",
    "    return printable\n",
    "\n",
    "def print_table(table, title):\n",
    "    printable = to_printable_table(table, title)\n",
    "    print(printable)\n",
    "\n",
    "def save_table(table, title, filename):\n",
    "    tgt_dir = os.path.join(DATA_SOURCE, FIGS_DIR)\n",
    "    tgt = os.path.join(tgt_dir, filename)    \n",
    "    printable = to_printable_table(table, title)\n",
    "    if not os.path.exists(tgt_dir):\n",
    "        os.makedirs(tgt_dir)\n",
    "    with open(tgt, 'w') as table_h:\n",
    "        table_h.write(printable)\n",
    "    print(f\"Saved to {tgt}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682fc2cf-68e9-44e2-b786-cb1da6b3b244",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mean, Median Mean with timeouts/errors\n",
    "def mean_med_overall(series):\n",
    "    times = [t for t in series if  (isinstance(t, float) or isinstance(t, int)) and t >= 0 and t < TIMEOUT]\n",
    "    times_with_timeout = [t if (isinstance(t, float) or isinstance(t, int)) and t >= 0 else TIMEOUT for t in series]\n",
    "    mean = round(numpy.mean(times or [-1]), 1)\n",
    "    mean_with_timeouts = round(numpy.mean(times_with_timeout or [-1]), 1)\n",
    "    median = round(numpy.median(times or [-1]), 1)\n",
    "    return (\n",
    "        f\"{mean:0.01f}\" if mean != -1 else f\"{'-':<4}\", \n",
    "        f\"{median:0.1f}\" if median != -1 else f\"{'-':<5}\", \n",
    "        f\"{mean_with_timeouts:0.1f}\" if mean != -1 else f\"{'-':<4}\"\n",
    "    )\n",
    "table = to_table(df, 'op', mean_med_overall, trim_rows=True)\n",
    "print_table(table, \"Average / Median / Average with Timeouts\")\n",
    "print()\n",
    "save_table(table, \"Average / Median / Average with Timeouts\", \"avg-med-avgt.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290390e9-ea6b-4edc-87f4-d817266fca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finished, Errors and Timeouts\n",
    "def fin_err_tim(series):\n",
    "    timeouts = [a for a in series if (isinstance(a, float) or isinstance(a, int)) and a >= TIMEOUT and not numpy.isnan(a) and a != 'ERR']\n",
    "    errors = [a for a in series if a == 'ERR']\n",
    "    times = [t for t in series if  (isinstance(t, float) or isinstance(t, int)) and t >= 0 and t < TIMEOUT]\n",
    "    return (\n",
    "        f\"{len(times):}\",\n",
    "        f\"{len(errors):}\",\n",
    "        f\"{len(timeouts):}\"\n",
    "    )\n",
    "table = to_table(df[df['op'] == 'runtime'], 'bench', fin_err_tim)\n",
    "print_table(table, \"Finished / Errors / Timeouts\")\n",
    "print()\n",
    "save_table(table, \"Finished / Errors / Timeouts\", \"fin-err-to.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae7d6e8-08d8-49f3-b607-3b4a62b97fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, Second, Third Quartiles\n",
    "def quartiles(series):\n",
    "    times = [t if (isinstance(t, float) or isinstance(t, int)) and t >= 0 and t < TIMEOUT else TIMEOUT for t in series]\n",
    "    first = numpy.quantile(times, 0.25)\n",
    "    second = numpy.quantile(times, 0.5)\n",
    "    third = numpy.quantile(times, 0.75)\n",
    "    iqr = third - first\n",
    "    return (\n",
    "        f\"{first:0.0f}\" if first < TIMEOUT else f\"{TIMEOUT}\", \n",
    "        f\"{second:0.0f}\" if second < TIMEOUT else f\"{TIMEOUT}\", \n",
    "        f\"{third:0.0f}\" if third < TIMEOUT else f\"{TIMEOUT}\"\n",
    "    )\n",
    "table = to_table(df, 'bench', quartiles, trim_rows=True)\n",
    "print_table(table, \"1st Quartile / Median / 3rd Quartile\")\n",
    "print()\n",
    "save_table(table, \"1st Quartile / Median / 3rd Quartile\", \"quartiles.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff20278d-91c7-4926-8c8a-23a0e9031666",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, Second, Third Quartiles\n",
    "def quartiles(series):\n",
    "    times = [t if (isinstance(t, float) or isinstance(t, int)) and t >= 0 and t < TIMEOUT else TIMEOUT for t in series]\n",
    "    first = numpy.quantile(times, 0.25)\n",
    "    second = numpy.quantile(times, 0.5)\n",
    "    third = numpy.quantile(times, 0.75)\n",
    "    iqr = third - first\n",
    "    return (\n",
    "        f\"{first:0.1f}\" if first < TIMEOUT else f\"{TIMEOUT}\", \n",
    "        f\"{second:0.1f}\" if second < TIMEOUT else f\"{TIMEOUT}\", \n",
    "        f\"{third:0.1f}\" if third < TIMEOUT else f\"{TIMEOUT}\"\n",
    "    )\n",
    "table = to_table(df, 'op', quartiles, trim_rows=True)\n",
    "print_table(table, \"1st Quartile / Median / 3rd Quartile per operation\")\n",
    "print()\n",
    "save_table(table, \"1st Quartile / Median / 3rd Quartile per operation\", \"quartiles-op.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95d37e-9623-461a-a821-5c1b3a2d0bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, Second, Third Quartiles\n",
    "def quartiles(series):\n",
    "    times = [t if (isinstance(t, float) or isinstance(t, int)) and t >= 0 and t < TIMEOUT else TIMEOUT for t in series]\n",
    "    first = numpy.quantile(times, 0.25)\n",
    "    second = numpy.quantile(times, 0.5)\n",
    "    third = numpy.quantile(times, 0.75)\n",
    "    iqr = third - first\n",
    "    return (\n",
    "        f\"{first:0.1f}\" if first < TIMEOUT else f\"{TIMEOUT}\", \n",
    "        f\"{second:0.1f}\" if second < TIMEOUT else f\"{TIMEOUT}\", \n",
    "        f\"{third:0.1f}\" if third < TIMEOUT else f\"{TIMEOUT}\"\n",
    "    )\n",
    "df['benchop'] = [f\"{o[:5]}/{''.join(a[0] for a in b.split('_'))}\" for b, o in zip(df['bench'], df['op'])]\n",
    "table = to_table(df, 'benchop', quartiles, trim_rows=True, trimsize=9)\n",
    "print_table(table, \"1st Quartile / Median / 3rd Quartile per op/bench\")\n",
    "print()\n",
    "save_table(table, \"1st Quartile / Median / 3rd Quartile per op/bench\", \"quartiles-benchop.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830e2a0b-77e0-4b69-8d17-0b261cd0bf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DONE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
