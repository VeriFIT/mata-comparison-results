{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d46f14ae-3472-4c82-b812-100d2b9ebd15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.output_area pre {white-space: pre;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# System Packages\n",
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import zip_longest\n",
    "import csv\n",
    "import re\n",
    "import progressbar\n",
    "import shutil\n",
    "\n",
    "# Data Analysis Packages\n",
    "import pandas\n",
    "import tabulate\n",
    "import seaborn\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# From imports\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Filtering warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "# Short hack for display of images in jupyter notebook\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>div.output_area pre {white-space: pre;}</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33e52c8-fcc9-468d-9fc2-f1486ab67931",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "The following is a helper function for saving figures to either `png`, `pdf` or some other format. It stores the results in `figs` dir, and creates any directories if missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f262d43f-974b-4e47-ac16-da74d9892c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGS_DIR = \"figs\"\n",
    "def save_figure(fig, ext=\".png\"):\n",
    "    \"\"\"Stores @p fig at `figs/fig.@ext`\"\"\"\n",
    "    tgt_dir = os.path.join(DATA_SOURCE, FIGS_DIR)\n",
    "    tgt = os.path.join(tgt_dir, fig + ext)    \n",
    "    if not os.path.exists(tgt_dir):\n",
    "        os.makedirs(tgt_dir)\n",
    "    print(f\"Saving to {tgt}\")\n",
    "    if ext == \".png\":\n",
    "        plt.savefig(tgt, backend=\"cairo\", bbox_inches=\"tight\", pad_inches=0.2)\n",
    "    elif ext == '.pdf':\n",
    "        plt.savefig(tgt, format='pdf', bbox_inches=\"tight\", pad_inches=0.2)\n",
    "    else:\n",
    "        plt.savefig(tgt, bbox_inches=\"tight\", pad_inches=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e215a-9365-4179-bca6-7a346cd2ac86",
   "metadata": {},
   "source": [
    "You can change `DATA_DIR` to different directory. The following will list all possible data sources, that can be used as input for creating dataframe with results. The chosen directory has to contain `.csv` files. We provide original results in `./data/tacas24` directory. Copy selected line, below and run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c35703b5-9d3c-4f16-bf63-9a29c870a4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_SOURCE = \"./data/experiments-09-18\"\n",
      "DATA_SOURCE = \"./data/experiments-09-19\"\n",
      "DATA_SOURCE = \"./data/experiments-09-21\"\n",
      "DATA_SOURCE = \"./data/experiments-09-23\"\n",
      "DATA_SOURCE = \"./data/experiments-09-25-concat\"\n",
      "DATA_SOURCE = \"./data/experiments-09-26-partial-testing\"\n",
      "DATA_SOURCE = \"./data/experiments-09-27\"\n",
      "DATA_SOURCE = \"./data/experiments-09-29-new-mata\"\n",
      "DATA_SOURCE = \"./data/experiments-09-30-parsing\"\n",
      "DATA_SOURCE = \"./data/experiments-10-01-mata-union\"\n",
      "DATA_SOURCE = \"./data/experiments-10-02\"\n",
      "DATA_SOURCE = \"./data/experiments-10-02-automata\"\n",
      "DATA_SOURCE = \"./data/experiments-10-02-parsing\"\n",
      "DATA_SOURCE = \"./data/experiments-10-04\"\n",
      "DATA_SOURCE = \"./data/experiments-10-04-sim\"\n",
      "DATA_SOURCE = \"./data/experiments-10-05-email-filter\"\n",
      "DATA_SOURCE = \"./data/experiments-10-05-email-filter-2\"\n",
      "DATA_SOURCE = \"./data/experiments-10-05-presburger\"\n",
      "DATA_SOURCE = \"./data/experiments-10-05-presburger-2\"\n",
      "DATA_SOURCE = \"./data/experiments-10-06\"\n",
      "DATA_SOURCE = \"./data/experiments-10-07\"\n",
      "DATA_SOURCE = \"./data/experiments-10-08-mata-inclusion\"\n",
      "DATA_SOURCE = \"./data/experiments-10-08-mata-three-inclusion-seq\"\n",
      "DATA_SOURCE = \"./data/experiments-10-08-mata-three-inclusions\"\n",
      "DATA_SOURCE = \"./data/experiments-10-08-mata-vs-awali\"\n",
      "DATA_SOURCE = \"./data/experiments-10-08-panda-parser\"\n",
      "DATA_SOURCE = \"./data/experiments-10-09-bc-intersect\"\n",
      "DATA_SOURCE = \"./data/experiments-10-09-ere\"\n",
      "DATA_SOURCE = \"./data/experiments-10-09-ere-2\"\n",
      "DATA_SOURCE = \"./data/experiments-10-09-inclusions\"\n",
      "DATA_SOURCE = \"./data/experiments-10-09-z3-intersect\"\n",
      "DATA_SOURCE = \"./data/experiments-10-10-full\"\n",
      "DATA_SOURCE = \"./data/experiments-10-16-automata-min\"\n",
      "DATA_SOURCE = \"./data/experiments-10-16-email-filter-seq\"\n",
      "DATA_SOURCE = \"./data/experiments-10-16-jalib\"\n",
      "DATA_SOURCE = \"./data/experiments-10-17-jalib-automata\"\n",
      "DATA_SOURCE = \"./data/experiments-16-10-automata-min-2\"\n",
      "DATA_SOURCE = \"./data/experiments-16-10-mintermization-time-in-automata\"\n",
      "DATA_SOURCE = \"./data/stats\"\n",
      "DATA_SOURCE = \"./data/stats-10-10\"\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"./data/\"\n",
    "for experiment_dir in os.listdir(DATA_DIR):\n",
    "    full_path = os.path.join(DATA_DIR, experiment_dir)\n",
    "    if os.path.isdir(full_path):\n",
    "        print(f'DATA_SOURCE = \"{full_path}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d298ce7-c10d-4197-a450-6ba3f5a7f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE = \"./data/experiments-10-10-full\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e768b8d-1e22-4fcf-9b8f-e8f9394b9844",
   "metadata": {},
   "source": [
    "## Creating DataFrame\n",
    "The following functions `to_operation`, `to_tool_and_lang` and `to_bench` serve to provide classification and translation of particular parts of results to notation used in paper (i.e. tools correspond to their name in paper, benchmarks to their naming in paper, and operations are unified, as we used different notations in different tools)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e252f0b-cd6e-4615-99b9-914296df4104",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERR = 60\n",
    "TIMEOUT = 60\n",
    "\n",
    "def to_operation(src, lang):\n",
    "    op = src.split('-')[-1]\n",
    "    if 'runtime' in op:\n",
    "        return 'runtime'\n",
    "    elif 'overall' in op:\n",
    "        return 'overall'\n",
    "    elif 'interpretation' in op:\n",
    "        return 'interpretation'\n",
    "    elif 'deter' in op:\n",
    "        return 'determization'\n",
    "    elif 'minterm' in op:\n",
    "        return 'minterm'\n",
    "    elif 'reduce' in op:\n",
    "        return 'reduce'\n",
    "    elif 'inter' in op:\n",
    "        return 'intersection'\n",
    "    elif 'union' in op or 'uni' in op:\n",
    "        return 'union'\n",
    "    elif ('construction' in op and lang != 'c++') or 'parsing' in op:\n",
    "        return 'parsing'\n",
    "    elif ('construction' in op and lang == 'c++') or 'conversion' in op:\n",
    "        return 'transform'\n",
    "    elif 'concat' in op:\n",
    "        return 'concatenation'\n",
    "    elif 'result' in op:\n",
    "        return 'result'\n",
    "    elif 'inclusion_check' == op or 'inclusion' == op:\n",
    "        return 'inclusion'\n",
    "    elif 'emptiness_check' == op or 'emptiness' == op:\n",
    "        return 'emptiness'\n",
    "    elif 'compl' == op or 'complementation' == op or 'complement' == op:\n",
    "        return 'complement'\n",
    "    elif 'trim' in op:\n",
    "        return 'trim'\n",
    "    print(f\"{src} unhandled\")\n",
    "    assert False\n",
    "\n",
    "def to_tool_and_lang(tool):\n",
    "    if 'mata-bin' in tool or 'stats' in tool:\n",
    "        return None, None\n",
    "    elif 'mata-0.111' in tool:\n",
    "        return \"mata-0.111\", \"c++\"\n",
    "    elif 'mata-0.112' in tool:\n",
    "        return \"mata-0.112\", \"c++\"\n",
    "    elif 'mata-0.113' in tool:\n",
    "        return \"mata-0.113\", \"c++\"\n",
    "    elif 'mata-sim' in tool:\n",
    "        return \"mata-sim\", \"c++\"\n",
    "    elif 'mata-old' in tool:\n",
    "        return \"mata-old\", \"c++\"\n",
    "    elif 'awali' in tool:\n",
    "        return 'awali', 'c++'\n",
    "    elif 'mona' in tool:\n",
    "        return 'mona', 'c++'\n",
    "    elif 'vata' in tool:\n",
    "        return 'vata', 'c++'\n",
    "    elif 'java-brics' in tool:\n",
    "        return 'brics', 'java'\n",
    "    elif 'java-automatalib-old' in tool:\n",
    "        return 'automatalib-old', 'java'\n",
    "    elif 'java-automata' in tool:\n",
    "        return 'automatalib', 'java'\n",
    "    elif 'pyfado' in tool:\n",
    "        return 'fado', 'python'\n",
    "    elif 'pyautomata-lib' in tool:\n",
    "        return 'automata.py', 'python'\n",
    "    elif 'pymata' in tool:\n",
    "        return '(py)mata', 'python'\n",
    "    elif 'automata-old' in tool:\n",
    "        return None, None\n",
    "    elif 'automata-min' in tool:\n",
    "        return 'automata.net', 'c#'\n",
    "    elif 'automata' in tool:\n",
    "        return 'automata.net-old', 'c#'\n",
    "    elif 'mata' in tool:\n",
    "        return 'mata', 'c++'\n",
    "    print(f\"{tool} unhandled\")\n",
    "    assert False\n",
    "\n",
    "def to_bench(bench, src):\n",
    "    if 'automata_inclusion' in bench:\n",
    "        return 'armc-incl'\n",
    "    elif 'comb/ere' in bench:\n",
    "        return 'b-smt'\n",
    "    elif ('cox/diff' in bench or 'cox/inter' in bench) and 'union' in src :\n",
    "        return 'param-union'\n",
    "    elif ('cox/diff' in bench or 'cox/inter' in bench) and 'cox-inter' in src :\n",
    "        return 'param-inter'\n",
    "    elif ('cox/diff' in bench or 'cox/inter' in bench) and 'cox-diff' in src :\n",
    "        return 'param-diff'\n",
    "    elif 'email_filter' in bench:\n",
    "        return 'email-filter'\n",
    "    elif 'z3-noodler' in bench:\n",
    "        if 'concat' in src:\n",
    "            return 'noodler-concat'\n",
    "        elif 'intersect' in src:\n",
    "            return 'noodler-inter'\n",
    "        else:\n",
    "            return 'noodler-compl'\n",
    "    elif 'presburger-explicit' in bench:\n",
    "        return 'lia-explicit'\n",
    "    elif 'presburger' in bench:\n",
    "        return 'lia-symbolic'\n",
    "    elif 'intersect' in bench:\n",
    "        return 'param-inter' if 'union' not in src else 'param-union'\n",
    "    print(f\"{bench} unhandled\")\n",
    "    assert False\n",
    "\n",
    "def to_value(val):\n",
    "    val = val.strip()\n",
    "    try:\n",
    "        return float(val)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    if val in ['EMPTY', \"NOT EMPTY\"]:\n",
    "        return val\n",
    "    elif val in ('false', 'False'):\n",
    "        return 'false'\n",
    "    elif val in ('true', 'True'):\n",
    "        return 'true'\n",
    "    elif val == 'ERR':\n",
    "        return 'ERR'\n",
    "    elif val == 'MISSING':\n",
    "        return numpy.NAN\n",
    "    elif val == 'TIMEOUT' or val == 'TO':\n",
    "        return TIMEOUT\n",
    "    print(f\"{val} unhandled\")\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed815ef-4e91-43cb-8592-0b2247b3d966",
   "metadata": {},
   "source": [
    "Master function for creating `pandas.DataFrame` from directory containing `csv` files.\n",
    "\n",
    "The `.csv` files are in the following structure:\n",
    "`instance;tool1-op1;tool1-op2;...tool1-opn;...toolm-opn`\n",
    "\n",
    "This is transformed into a following dataframe:\n",
    "`bench | input | tool | lang | op | time`\n",
    "Where:\n",
    "  1. `bench` corresponds to classification of benchmark used in paper (returned by `to_bench` function);\n",
    "  2. `input` corresponds to instance of the benchmark, i.e. the input automata used for evaluation;\n",
    "  3. `tool` corresponds to naming of the tool (returned by `to_tool_and_lang`);\n",
    "  4. `lang` corresponds to language of the tool (returned by `to_tool_and_lang`);\n",
    "  5. `op` corresponds to individual operations, such as `intersection` or `union` (returned by `to_operation`); and;\n",
    "  6. `time` corresponds to the value of the operation: either float value; `TO`, if timeout happened; `MISSING` if the instance was missing some automata; `ERR` if error happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86b1f1d9-ff65-4aa9-9ae4-78b319db16c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (65 of 65) |########################| Elapsed Time: 0:00:05 Time:  0:00:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 bench                                              input  \\\n",
      "0            armc-incl  /home/experiments/nfa-bench/benchmarks/automat...   \n",
      "1            armc-incl  /home/experiments/nfa-bench/benchmarks/automat...   \n",
      "2            armc-incl  /home/experiments/nfa-bench/benchmarks/automat...   \n",
      "3            armc-incl  /home/experiments/nfa-bench/benchmarks/automat...   \n",
      "4            armc-incl  /home/experiments/nfa-bench/benchmarks/automat...   \n",
      "...                ...                                                ...   \n",
      "857862  noodler-concat  /home/experiments/nfa-bench/benchmarks/z3-nood...   \n",
      "857863  noodler-concat  /home/experiments/nfa-bench/benchmarks/z3-nood...   \n",
      "857864  noodler-concat  /home/experiments/nfa-bench/benchmarks/z3-nood...   \n",
      "857865  noodler-concat  /home/experiments/nfa-bench/benchmarks/z3-nood...   \n",
      "857866  noodler-concat  /home/experiments/nfa-bench/benchmarks/z3-nood...   \n",
      "\n",
      "                    tool lang             op      time  \n",
      "0       automata.net-old   c#        runtime       0.3  \n",
      "1       automata.net-old   c#        parsing  0.213059  \n",
      "2       automata.net-old   c#           trim  0.008389  \n",
      "3       automata.net-old   c#      inclusion  0.052707  \n",
      "4       automata.net-old   c#         result     false  \n",
      "...                  ...  ...            ...       ...  \n",
      "857862          mata-sim  c++  concatenation  0.005427  \n",
      "857863          mata-sim  c++           trim  0.002827  \n",
      "857864          mata-sim  c++      emptiness  0.000946  \n",
      "857865          mata-sim  c++         result     false  \n",
      "857866          mata-sim  c++        overall  0.236812  \n",
      "\n",
      "[857867 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "HEADERS = [\"bench\", \"input\", \"tool\", \"lang\", \"op\", \"time\"]\n",
    "TIMEOUT = 60\n",
    "TIMEOUT_REGEX = re.compile(\"timeout-(\\d+)\")\n",
    "processed = defaultdict(set)\n",
    "op_map = defaultdict(list)\n",
    "bench_map = defaultdict(set)\n",
    "\n",
    "def to_pandas(src_dir):\n",
    "    global TIMEOUT\n",
    "    data = []\n",
    "    for csv_source in progressbar.progressbar(os.listdir(src_dir)):\n",
    "        if csv_source.endswith('.csv'):\n",
    "            if timeout := TIMEOUT_REGEX.search(csv_source):\n",
    "                TIMEOUT = int(timeout.group(1))\n",
    "            with open(os.path.join(src_dir, csv_source), 'r', newline='') as csvfile:\n",
    "                try:\n",
    "                    csv_reader = csv.reader(csvfile, delimiter=';')\n",
    "                    head = next(csv_reader)\n",
    "                    for row in csv_reader:\n",
    "                        bench = to_bench(row[0], csv_source) # bench\n",
    "                        bench_map[(row[0], bench)].add(csv_source)\n",
    "                        inputs = row[0] # inputs\n",
    "                        for i, val in enumerate(row[1:], 1):\n",
    "                            tool, lang = to_tool_and_lang(head[i]) # tool, lang\n",
    "                            if not tool:\n",
    "                                continue\n",
    "                            op = to_operation(head[i], lang) # op\n",
    "                            op_map[op].append(head[i])\n",
    "                            val = to_value(val)\n",
    "                            data.append([bench, inputs, tool, lang, op, val])\n",
    "                except StopIteration:\n",
    "                    pass\n",
    "    return pandas.DataFrame(data, columns=HEADERS)\n",
    "df = to_pandas(DATA_SOURCE)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9101b1d5-6461-446e-afad-a4627fd48ee8",
   "metadata": {},
   "source": [
    "From the loaded data we infer a `fairest-of-them-all` time, which corresponds to summary of all automata operations solved by particular instance of benchmark. We believe this is fairest comparison (fairer than `runtime` measured by our `pycobench` benchmarking script), as it does not contain parsing, converting between formats and other boilerplate operations not related to the actual time of algorithms, or other automata manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a92c4d1-2c79-4202-81a4-fdf086327baa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_float' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m     fairest_runtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m operations:\n\u001b[0;32m---> 39\u001b[0m         fairest_runtime \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mto_float\u001b[49m(series[series[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mop\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m op][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     40\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(fairest_runtime)\n\u001b[1;32m     42\u001b[0m df_with_fair_time \u001b[38;5;241m=\u001b[39m pandas\u001b[38;5;241m.\u001b[39mDataFrame(data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'to_float' is not defined"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'bench': [],\n",
    "    'input': [],\n",
    "    'tool': [],\n",
    "    'lang': [],\n",
    "    'op': [],\n",
    "    'time': []\n",
    "}\n",
    "operations = [\n",
    "    'complement',      \n",
    "    'trim', \n",
    "    'emptiness',  \n",
    "    'inclusion',\n",
    "    'concatenation', \n",
    "    'intersection', \n",
    "    'union',\n",
    "    'determization',  \n",
    "    'reduce', \n",
    "]\n",
    "\n",
    "for grp, series in df.groupby(['bench', 'input', 'tool']):\n",
    "    data['bench'].append(grp[0])\n",
    "    data['input'].append(grp[1])\n",
    "    data['tool'].append(grp[2])\n",
    "    data['lang'].append(list(series['lang'])[0])\n",
    "    data['op'].append('fairest-of-them-all')\n",
    "\n",
    "    pyco_runtime = list(series[series['op'] == 'runtime']['time'])\n",
    "    if len(pyco_runtime) != 1:\n",
    "        print(f\"{list(series.items())=}\")\n",
    "        print(f\"{pyco_runtime=}\")\n",
    "        assert False\n",
    "    if pyco_runtime[0] == TIMEOUT or pyco_runtime[0] == 'ERR':\n",
    "        data['time'].append(TIMEOUT)\n",
    "        continue\n",
    "        \n",
    "    fairest_runtime = 0\n",
    "    for op in operations:\n",
    "        fairest_runtime += to_float(series[series['op'] == op]['time'], 0)\n",
    "    data['time'].append(fairest_runtime)\n",
    "    \n",
    "df_with_fair_time = pandas.DataFrame(data)\n",
    "df = pandas.concat([df, df_with_fair_time])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e676e8a-1ff8-42ec-9ea2-c9582dd6f882",
   "metadata": {},
   "source": [
    "The following is a helper function used for computing the cactus plot: the times are sorted, and summed until timeouts are encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c159f8-fc68-4871-bc95-d7a7f16976d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_generator(series, timeout=None):\n",
    "    \"\"\"Cumulatively sums the @p series wrt @p timeout\"\"\"\n",
    "    sum = 0\n",
    "    series = sorted(\n",
    "        [a if isinstance(a, float | int) else numpy.NAN for a in series['time']],\n",
    "        key = lambda x: float('inf') if numpy.isnan(x) else x\n",
    "    )\n",
    "    for num in sorted(series):\n",
    "        if numpy.isnan(num):\n",
    "            yield None\n",
    "        if timeout and num >= timeout:\n",
    "            yield None\n",
    "        else:\n",
    "            sum += num\n",
    "            yield sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848d869b-3024-4c4a-a5ca-e07d0052e237",
   "metadata": {},
   "source": [
    "Setting of colours and axis style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea06ab5d-51a7-4f03-958f-2d0e8a6fdcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = sorted(t for t in set(df['tool']))\n",
    "tools = ['mata'] + [t for t in tools if t != 'mata']\n",
    "tool_len = len(tools)\n",
    "color_map = {\n",
    "    t: c for (t, c) in zip(tools, mpl.colormaps['tab10'].resampled(tool_len).colors)\n",
    "}\n",
    "axis_scale = \"symlog\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f450fc1b-447f-4f56-a482-52abd4196781",
   "metadata": {},
   "source": [
    "### Figure 4\n",
    "The following code expects that all 10 benchmarks were run. If you ran less benchmarks, the output might be incorrect or mangled. The generated figure corresponds to Figure 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e52f54-4463-4abd-9457-02b181aeead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_list = sorted(list(set(list(df['bench']))))\n",
    "\n",
    "item_no = len(bench_list)\n",
    "item_per_row = 3\n",
    "x_dim = item_no // item_per_row + 1\n",
    "y_dim = min(item_no, item_per_row)\n",
    "\n",
    "mosaic = \"\"\"\n",
    "  ABC\n",
    "  DKE\n",
    "  FKG\n",
    "  HIJ\n",
    "\"\"\"\n",
    "\n",
    "mosaics = \"ABCDEFGHIJ\"\n",
    "hr = [1, 1, 1, 1]\n",
    "log = \"\"\n",
    "\n",
    "seaborn.set_style('white', {'axes.grid': True, 'grid.linestyle': '--', 'lines.solid_capstyle': 'butt'})\n",
    "\n",
    "sum_op, sum_name = (sum_generator, \"sum\")\n",
    "op = 'fairest-of-them-all'\n",
    "fig, ax = plt.subplot_mosaic(mosaic, figsize=(x_dim*6, y_dim*5), height_ratios=hr)\n",
    "plt.subplots_adjust(top=0.99, bottom=0.01, hspace=0.4, wspace=0.1)\n",
    "\n",
    "i = 0\n",
    "for grp in bench_list:\n",
    "    series = df[df['bench'] == grp]\n",
    "    series = series[series['op'] == op]\n",
    "    grp_name = f\"{grp}\"\n",
    "    k = mosaics[i]\n",
    "    \n",
    "    idata = {}\n",
    "    for tool, values in series.groupby('tool'):\n",
    "        idata[tool] = list(sum_op(values, timeout=TIMEOUT))\n",
    "\n",
    "    order = ['mata', 'mata-sim', 'awali', 'mona', 'vata',  'automata.net', 'automata.net-min', 'brics', 'automatalib', 'fado', 'automata.py'][::-1]\n",
    "    data = {}\n",
    "    for key in order:\n",
    "        if key not in idata.keys():\n",
    "            continue\n",
    "        data[key] = idata[key]\n",
    "            \n",
    "    g = seaborn.lineplot(\n",
    "        data, linewidth=5, palette=color_map, dashes=\"\", ax=ax[k] if item_no > 1 else ax\n",
    "    )\n",
    "\n",
    "    g.legend([], [], frameon=False)\n",
    "    g.set(yscale=axis_scale)\n",
    "    g.set_xticklabels(g.get_xticklabels(), rotation=30, fontsize=18)\n",
    "    g.set_yticklabels(g.get_yticklabels(), fontsize=18)\n",
    "    g.set_title(\n",
    "        f\"{grp}\", \n",
    "        weight='bold',\n",
    "        fontsize=20\n",
    "    )\n",
    "    if k in \"ADFH\":\n",
    "        g.set_ylabel(\"time [s]\", fontsize=18)\n",
    "    if k in \"HIJ\":\n",
    "        g.set_xlabel(\"instance\", fontsize=18)\n",
    "    \n",
    "    \n",
    "    x_lim_min, x_lim_max = g.get_xlim()\n",
    "    g.set_xlim((x_lim_min, x_lim_max))\n",
    "    y_lim_min, y_lim_max = g.get_ylim()\n",
    "    g.set_ylim((0, max(y_lim_min, y_lim_max)))\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "ax[\"K\"].set(xlabel=None)\n",
    "ax[\"K\"].set(yticklabels=[])\n",
    "ax[\"K\"].set(xticklabels=[])\n",
    "ax[\"K\"].set(xticks=[])\n",
    "ax[\"K\"].set(yticks=[])\n",
    "ax[\"K\"].spines['top'].set_visible(False)\n",
    "ax[\"K\"].spines['bottom'].set_visible(False) \n",
    "ax[\"K\"].spines['left'].set_visible(False) \n",
    "ax[\"K\"].spines['right'].set_visible(False) \n",
    "ax[\"K\"].legend(\n",
    "    handles=[\n",
    "        Line2D(\n",
    "            [0], [0], color='w', marker='o', markerfacecolor=color_map[tool], label=f\"{tool}\", \n",
    "            markersize=22,\n",
    "        )\n",
    "        for tool in sorted(color_map.keys())\n",
    "    ], ncols=1, loc='center', fontsize='24', frameon=False, labelspacing=1\n",
    ") \n",
    "save_figure(f\"paper-cactus-plot-per-bench-{sum_name}-{op}-4-x-3\")\n",
    "save_figure(f\"paper-cactus-plot-per-bench-{sum_name}-{op}-4-x-3\", ext=\".pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a904ad-6e87-4aa3-9f18-f6c1258a09d3",
   "metadata": {},
   "source": [
    "### Figure 5\n",
    "The following code expects that most of the benchmarks were run. If you ran less benchmarks, the output might be incorrect or mangled. The generated figure corresponds to Figure 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734a39a6-9c79-4636-bbdb-721cdb7c0d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "op_list = sorted(list(set(list(df['op']))))\n",
    "op_list = [\n",
    "    'complement',\n",
    "    'trim', \n",
    "    'emptiness',                    \n",
    "    'inclusion',\n",
    "    'concatenation', \n",
    "    'intersection', \n",
    "    'union'\n",
    "]\n",
    "item_no = len(op_list)\n",
    "x_dim = item_no // 3 + 1\n",
    "y_dim = min(item_no, 3)\n",
    "\n",
    "mosaic = \"\"\"\n",
    "  AKB\n",
    "  CKD\n",
    "  EFG\n",
    "\"\"\"\n",
    "\n",
    "seaborn.set_style('white', {'axes.grid': True, 'grid.linestyle': '--', 'lines.solid_capstyle': 'butt'})\n",
    "\n",
    "mosaics = \"ABCDEFGHIJ\"\n",
    "hr = [1, 1, 1]\n",
    "\n",
    "for sum_op, sum_name in [(sum_generator, \"sum\")]:\n",
    "    #fig, ax = plt.subplots(x_dim, y_dim, figsize=(x_dim * 5, y_dim * 3))\n",
    "    fig, ax = plt.subplot_mosaic(mosaic, figsize=(x_dim * 6, y_dim * 3), height_ratios=hr)\n",
    "    plt.subplots_adjust(top=0.99, bottom=0.01, hspace=0.4, wspace=0.20)\n",
    "    \n",
    "    i = 0\n",
    "    for grp in op_list:\n",
    "        series = df[df['op'] == grp]\n",
    "        grp_name = f\"{grp}\"\n",
    "        k = mosaics[i]\n",
    "        \n",
    "        idata = {}\n",
    "        for tool, values in series.groupby('tool'):\n",
    "            idata[tool] = list(sum_op(values, timeout=TIMEOUT))\n",
    "        order = ['mata', 'mata-sim', 'awali', 'mona', 'vata',  'automata.net', 'brics', 'automatalib', 'fado', 'automata.py'][::-1]\n",
    "        \n",
    "        data = {}\n",
    "        for key in order:\n",
    "            if key not in idata.keys():\n",
    "                continue\n",
    "            data[key] = idata[key]\n",
    "        g = seaborn.lineplot(\n",
    "            data, linewidth=3.5, palette=color_map, dashes=\"\", ax=ax[k] if item_no > 1 else ax\n",
    "        )\n",
    "        g.legend([], [], frameon=False)\n",
    "        \n",
    "        g.set(yscale=axis_scale)\n",
    "        g.set_xticklabels(g.get_xticklabels(), rotation=30, fontsize=18)\n",
    "        g.set_yticklabels(g.get_yticklabels(), fontsize=18)\n",
    "        g.set_title(\n",
    "            f\"{grp}\", \n",
    "            weight='bold',\n",
    "            #x=0.05,\n",
    "            fontsize=20\n",
    "        )\n",
    "        if k in \"ACE\":\n",
    "            g.set_ylabel(\"time [s]\", fontsize=18)\n",
    "        if k in \"EFG\":\n",
    "            g.set_xlabel(\"instance\", fontsize=18)\n",
    "        \n",
    "        #seaborn.move_legend(g, \"upper left\", bbox_to_anchor=(0., 1), frameon=False)\n",
    "        x_lim_min, x_lim_max = g.get_xlim()\n",
    "        g.set_xlim((x_lim_min, x_lim_max))\n",
    "        y_lim_min, y_lim_max = g.get_ylim()\n",
    "        g.set_ylim((0, max(y_lim_min, y_lim_max)))\n",
    "\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    ax[\"K\"].set(xlabel=None)\n",
    "    ax[\"K\"].set(yticklabels=[])\n",
    "    ax[\"K\"].set(xticklabels=[])\n",
    "    ax[\"K\"].set(xticks=[])\n",
    "    ax[\"K\"].set(yticks=[])\n",
    "    ax[\"K\"].spines['top'].set_visible(False)\n",
    "    ax[\"K\"].spines['bottom'].set_visible(False) \n",
    "    ax[\"K\"].spines['left'].set_visible(False) \n",
    "    ax[\"K\"].spines['right'].set_visible(False) \n",
    "    ax[\"K\"].legend(\n",
    "        handles=[\n",
    "            Line2D(\n",
    "                [0], [0], color='w', marker='o', markerfacecolor=color_map[tool], label=f\"{tool}\", \n",
    "                markersize=20,\n",
    "            )\n",
    "            for tool in sorted(color_map.keys())\n",
    "        ], ncols=1, loc='center left', fontsize='22', frameon=False, labelspacing=1\n",
    "    ) \n",
    "    save_figure(f\"paper-cactus-plot-per-operation-{sum_name}\")\n",
    "    save_figure(f\"paper-cactus-plot-per-operation-{sum_name}\", ext=\".pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af39d8e-8f75-41f6-8101-af375634ce74",
   "metadata": {},
   "source": [
    "### Tables\n",
    "\n",
    "The following contains helper functions for outputing tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2559904d-66af-4794-9804-3992447fb72d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def to_multicol(value, i, size=3):\n",
    "    cc = 'h' if i % 2 == 0 else 'c'\n",
    "    return f'\\\\multicolumn{{{size}}}{{{cc}}}{{{value}}}'\n",
    "\n",
    "def to_table(df, rows, aggregation, limit_tools, val_size, valid_values=None):\n",
    "    tools = ['mata', 'mata-0.111', 'mata-0.112', 'mata-0.113', 'mata-old', 'mata-sim', 'awali', 'mona', 'vata',  'automata.net', 'brics', 'automatalib', 'fado', 'automata.py', '(py)mata']\n",
    "    tools = [t for t in tools if t in set(df['tool']) and t in limit_tools]\n",
    "    data = {\n",
    "        grp: [grp] + [to_multicol('-', i, val_size) for i in range(len(tools))] for grp in set(df[rows]) \n",
    "        if valid_values == None or grp in valid_values\n",
    "    }\n",
    "    for grp, series in df.groupby([rows, 'tool'] if not isinstance(rows, list) else rows + ['tool']):\n",
    "        if (valid_values != None and grp[0] not in valid_values) or grp[1] not in tools:\n",
    "            continue\n",
    "        vals = aggregation(series['time'])\n",
    "        data[grp[0]][tools.index(grp[1]) + 1] = \" & \".join(vals)\n",
    "    return tabulate.tabulate(\n",
    "        sorted(data.values()), headers=[\n",
    "            \"\\\\textbf{operation}\" if rows == 'op' else \"\\\\textbf{benchmark}\"    \n",
    "        ] + [\n",
    "            to_multicol(f\"\\\\textbf{{{t}}}\", i, val_size) for i, t in enumerate(tools)\n",
    "        ], tablefmt='latex_raw'\n",
    "    )\n",
    "\n",
    "def save_table(table, filename):\n",
    "    tgt_dir = os.path.join(DATA_SOURCE, FIGS_DIR)\n",
    "    tgt = os.path.join(tgt_dir, filename)    \n",
    "    if not os.path.exists(tgt_dir):\n",
    "        os.makedirs(tgt_dir)\n",
    "    with open(tgt, 'w') as table_h:\n",
    "        lines = table.split('\\n')[2:-2]\n",
    "        lines[1] = '\\\\midrule'\n",
    "        lines = lines + ['\\\\bottomrule']\n",
    "        table_h.write('\\n'.join(lines))\n",
    "    print(f\"Saved to {tgt}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4000d3c1-9569-48a1-a5cf-8acc71da9ee9",
   "metadata": {},
   "source": [
    "This prints Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682fc2cf-68e9-44e2-b786-cb1da6b3b244",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mean, Median Mean with timeouts/errors\n",
    "def to_cell(val):\n",
    "    if val == 0:\n",
    "        return \"$\\overline{0}$\"\n",
    "    if val < TIMEOUT * 1000: \n",
    "        if val >= 1000:\n",
    "            return f\"{int(round(val / 1000, 0))} s\"\n",
    "        else:\n",
    "            return f\"{val}\"\n",
    "    else:\n",
    "        return f\"TO\"\n",
    "\n",
    "def stats(series):\n",
    "    times = [t for t in series if  (isinstance(t, float) or isinstance(t, int)) and t >= 0 and t < TIMEOUT]\n",
    "    #timeouts = [t for t in series if ((isinstance(t, float) or isinstance(t, int)) and t >= TIMEOUT)]\n",
    "    timeouts = [a for a in series if ((isinstance(a, float) or isinstance(a, int)) and (a >= TIMEOUT)) or a == 'ERR']\n",
    "\n",
    "    times_with_timeout = [t if (isinstance(t, float) or isinstance(t, int)) and t >= 0 else TIMEOUT for t in series]\n",
    "\n",
    "    mean = int(round(1000 *numpy.mean(times or [60]), 6))\n",
    "    #first = int(1000 * round(numpy.quantile(times_with_timeout, 0.25), 3))\n",
    "    first = int(round(1000 * numpy.quantile(times_with_timeout, 0.5), 6))\n",
    "    #third = int(1000 * round(numpy.quantile(times_with_timeout, 0.75), 3))\n",
    "    third = int(round(1000 * numpy.std(times), 6))\n",
    "\n",
    "    if with_to:\n",
    "        return (\n",
    "            f\"{len(timeouts)}\",\n",
    "            to_cell(mean),\n",
    "            to_cell(first),\n",
    "            to_cell(third),\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            to_cell(mean),\n",
    "            to_cell(first),\n",
    "            to_cell(third),\n",
    "        )\n",
    "valid_values = [\n",
    "    'complement', 'trim', 'emptiness', 'inclusion', 'concatenation', 'intersection', 'union'\n",
    "]\n",
    "\n",
    "with_to = False\n",
    "table = to_table(df, 'op', stats, limit_tools=['mata', 'awali', 'vata', 'mona', 'automata.net'], val_size=3, valid_values=valid_values)\n",
    "print(table)\n",
    "save_table(table, \"stats-per-op-1.tex\")\n",
    "print()\n",
    "table = to_table(df, 'op', stats, limit_tools=['mata', 'brics', 'automatalib', 'fado', 'automata.py'], val_size=3, valid_values=valid_values)\n",
    "print(table)\n",
    "save_table(table, \"stats-per-op-2.tex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeee9af-50e0-4d73-aa41-f6eb24e162f3",
   "metadata": {},
   "source": [
    "This outputs Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae7d6e8-08d8-49f3-b607-3b4a62b97fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_to = True\n",
    "table = to_table(df[df['op'] == 'fairest-of-them-all'], 'bench', stats, limit_tools=['mata', 'awali', 'vata', 'mona', 'automata.net'], val_size=4, valid_values=None)\n",
    "print(table)\n",
    "save_table(table, \"stats-per-bench-1.tex\")\n",
    "print()\n",
    "table = to_table(df[df['op'] == 'fairest-of-them-all'], 'bench', stats, limit_tools=['mata', 'brics', 'automatalib', 'fado', 'automata.py'], val_size=4, valid_values=None)\n",
    "print(table)\n",
    "save_table(table, \"stats-per-bench-2.tex\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab596746-db66-4519-975f-31baf891ee4e",
   "metadata": {},
   "source": [
    "This outputs Table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d9fed0-6bea-42f2-9043-226a6e70aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_stats(series):\n",
    "    d = {}\n",
    "    for k, v in series.iterrows():\n",
    "        assert v['input'] not in d.keys()\n",
    "        d[v['input']] = v['time']\n",
    "    return d\n",
    "def has_finished(val):\n",
    "    return isinstance(val, int | float) and 0 < float(val) < TIMEOUT\n",
    "def compute_relative(mata_d, other_d):\n",
    "    mata_sum = 0\n",
    "    other_sum = 0\n",
    "    for key in mata_d.keys():\n",
    "        mata_val = mata_d[key]\n",
    "        if key not in other_d.keys():\n",
    "            print(f\"missing: {key}\")\n",
    "            print(other_d.keys())\n",
    "            assert False\n",
    "        other_val = other_d[key]\n",
    "        if has_finished(mata_val) and has_finished(other_val):\n",
    "            mata_sum += mata_val\n",
    "            other_sum += other_val\n",
    "    return round(other_sum / mata_sum, 2) if mata_sum != 0 else '-'\n",
    "    \n",
    "def to_relative_table(df, rows, aggregation):\n",
    "    tools = ['mata', 'mata-0.111', 'mata-0.112', 'mata-0.113', 'mata-old', 'mata-sim', 'awali', 'mona', 'vata',  'automata.net', 'brics', 'automatalib-old', 'automatalib', 'fado', 'automata.py', '(py)mata']\n",
    "    tools = [t for t in tools if t in set(df['tool'])]\n",
    "    data = {\n",
    "        grp: [grp] + ['-' for i in range(len(tools))] for grp in set(df[rows]) if grp != 'result' and 'result' not in grp\n",
    "    }\n",
    "    for grp, series in df.groupby([rows, 'tool'] if not isinstance(rows, list) else rows + ['tool']):\n",
    "        if grp[0] == 'result' or 'result' in grp[0]:\n",
    "            continue\n",
    "        vals = aggregation(series[['time', 'input']])\n",
    "        data[grp[0]][tools.index(grp[1]) + 1] = vals\n",
    "    for key, vals in data.items():\n",
    "        data[key] = [vals[0]] + [\n",
    "            '-' if val == '-' else f\"{compute_relative(vals[1], val)}\" for val in vals[1:]\n",
    "        ]        \n",
    "    return tabulate.tabulate(\n",
    "        sorted(data.values()), headers=[rows] + tools, tablefmt='latex'\n",
    "    )    \n",
    "with_to = True\n",
    "cut = df[df['op'] == 'fairest-of-them-all']\n",
    "table = to_relative_table(cut, 'bench', relative_stats)\n",
    "print(table)\n",
    "print()\n",
    "save_table(table, \"stats-relative.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830e2a0b-77e0-4b69-8d17-0b261cd0bf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DONE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
